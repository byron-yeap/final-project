{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import nltk.stem as ns\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import seaborn as sns\n",
    "# !pip install spacy\n",
    "import spacy\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer,CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "# plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "\n",
    "# !pip list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    # 移除标点符号\n",
    "    punctuation_zh = r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~“”？，！【】（）、。：；’‘……￥·\"\"\"\n",
    "    dicts = {i: '' for i in punctuation + punctuation_zh}\n",
    "    punc_table = str.maketrans(dicts)\n",
    "    new_text = text.translate(punc_table)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "lst_dics = []\n",
    "with open (\"SMSSpamCollection.SMSSpamCollection\", mode='r', errors='ignore', encoding='utf8') as f: \n",
    "#     for dic in json_file: \n",
    "#         lst_dics.append( json.loads(dic) )\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        lint_split = line.split('\\t')\n",
    "        label = lint_split[0]\n",
    "        text = remove_punc(lint_split[1])\n",
    "        lst_dics.append( {\"label\": label, \"text(Original)\": text} )\n",
    "# lst_dics[0]\n",
    "\n",
    "dtf = pd.DataFrame(lst_dics)\n",
    "# 创建dtf\n",
    "\n",
    "# dtf = dtf.rename(columns={\"label\":\" category \", \"text\":\" content \"})\n",
    "# # 重命名列\n",
    "\n",
    "dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() \n",
    "fig.suptitle(\"The Counts of Both Kinds (total: %s)\" % dtf[\"label\"].count(), fontsize=12) \n",
    "dtf[\"label\"].reset_index().groupby(\"label\").count().sort_values(by= \n",
    "       \"index\").plot(kind= \"barh\", legend=False, ax=ax).grid(axis='x') \n",
    "\n",
    "count = []\n",
    "count.append( dtf[ dtf[\"label\"].isin(['ham']) ][\"label\"].count() )\n",
    "count.append( dtf[ dtf[\"label\"].isin(['spam']) ][\"label\"].count() )\n",
    "\n",
    "for i in range(2):\n",
    "    plt.text(count[i]-200,count[i]/4000 + 0.11,\"%s\"% count[i],va='center')\n",
    "    \n",
    "ax.set(ylabel=\"Label\", xlabel=\"The Number of The Messages\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 词性还原\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "lemmatizer = ns.WordNetLemmatizer()\n",
    "\n",
    "def lemma(sentences):\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        lemmas_sent = []\n",
    "        tokens = word_tokenize(sentence)  # 分词\n",
    "#         print(tokens)\n",
    "        for item in tokens:\n",
    "            if re.search(r'\\d', item):\n",
    "                tokens.remove(item)\n",
    "        tagged_sent = pos_tag(tokens)  # 获取单词词性\n",
    "        for tag in tagged_sent:\n",
    "            wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "            lemmas_sent.append(lemmatizer.lemmatize(tag[0], pos=wordnet_pos))  # 词形还原\n",
    "        new_sentences.append(' '.join(lemmas_sent))\n",
    "    return new_sentences\n",
    "\n",
    "text = []\n",
    "for i in dtf[\"text(Original)\"]:\n",
    "    i = ' '.join([item for item in word_tokenize(i) if item.lower() not in stop_words])\n",
    "    text.append( i.lower() )\n",
    "    \n",
    "textLemma = lemma(text)\n",
    "\n",
    "dtf[\"text(Preprocessing)\"] = textLemma\n",
    "dtf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(dtf_input):\n",
    "    min = np.min(dtf_input)\n",
    "    max = np.max(dtf_input)\n",
    "    return dtf_input.apply(lambda x: (x - min) / (max - min))\n",
    "\n",
    "df = pd.DataFrame(lst_dics)\n",
    "df['word_count'] = dtf[\"text(Original)\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "df['char_count'] = dtf[\"text(Original)\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "dtf['word_count'] = norm(dtf[\"text(Original)\"].apply(lambda x: len(str(x).split(\" \"))))\n",
    "dtf['char_count'] = norm(dtf[\"text(Original)\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \"))))\n",
    "dtf['avg_word_length'] = norm(df['char_count'] / df['word_count'])\n",
    "dtf['pound_count'] = norm(dtf[\"text(Original)\"].apply(lambda x: len(str(x).split(\"£\"))-1))\n",
    "dtf['capital_count'] = norm(dtf[\"text(Original)\"].apply(lambda x: sum(char.isupper() for char in str(x))))\n",
    "dtf['digit_count'] = norm(dtf[\"text(Original)\"].apply(lambda x: sum(char.isdigit() for char in str(x))))\n",
    "dtf['phone_count'] = norm(dtf[\"text(Original)\"].apply(lambda x: len(re.compile(r\"(?:^|[^\\d])(0\\d{10})(?:$|[^\\d])\").findall(x))))\n",
    "dtf['url'] = norm(dtf[\"text(Original)\"].apply(lambda x: 1 if \"www\" in x or \"http\" in x or \".uk\" in x or \".com\" in x else 0))\n",
    "\n",
    "dtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram & KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x, y = \"word_count\", \"label\"\n",
    "# x, y = \"tags_ORDINAL\", \"label\"\n",
    "# x, y = \"tags_ORDINAL\", \"label\"\n",
    "# [\"call later\", \"please call\", \"gon na\", \"try contact\", \"get\", \"go\", \"im\", \"come\", \"free\", \"txt\", \"mobile\"]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2) \n",
    "fig.suptitle(x, fontsize=15) \n",
    "for i in dtf[y].unique(): \n",
    "    # 直方图和密度\n",
    "    sns.distplot(dtf[dtf[y]==i][x], hist=True, kde=False, \n",
    "                 hist_kws={\"alpha\":0.8}, \n",
    "                 axlabel=\"Histogram\", ax=ax[0])\n",
    "    sns.distplot(dtf[dtf[y]==i][x], hist=False, kde=True, \n",
    "                 kde_kws={\"shade\":True}, axlabel=\"Kernel Density Estimation\",   \n",
    "                 ax=ax[1])\n",
    "\n",
    "    \n",
    "ax[0].grid(True) \n",
    "ax [0].legend(dtf[y].unique()) \n",
    "ax[0].set(ylabel=\"SMS Message Counts\", xlabel=\"SMS Message \"+ x +\"'s Value\\n\\nHistogram\")\n",
    "ax[1].grid(True) \n",
    "ax [1].legend(dtf[y].unique()) \n",
    "ax[1].set(ylabel=\"Density\", xlabel=\"SMS Message \"+ x +\"'s Value\\n\\nKDE\")\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()\n",
    "\n",
    "# 两图横坐标为 x 属性（归一化后）的值\n",
    "# 直方图纵坐标为 x 属性为该值的 项数的统计和\n",
    "# 核密度纵坐标为 密度，并不直接表达概率，我们需要计算的是曲线下方的面积。这个面积在直方图里就是宽度乘以高度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtf[\"sentiment\"] = norm(dtf[\"text(Preprocessing)\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.polarity))\n",
    "dtf\n",
    "# print(dtf[\"text\"].iloc[0], \" --> \", dtf[\"sentiment\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf[[ \"label\", \"text(Original)\", \"text(Preprocessing)\", \"sentiment\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named-Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 调用\n",
    "ner = spacy.load(\"en_core_web_lg\")\n",
    "## 打标签\n",
    "txt = dtf[\"text(Original)\"].iloc[0]\n",
    "doc = ner(txt)\n",
    "## 展示结果\n",
    "spacy.displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 标识文本并将标识导出到列表中\n",
    "dtf[\"tags\"] = dtf[\"text(Original)\"].apply(lambda x: [(tag.text, tag.label_) \n",
    "                                for tag in ner(x).ents] )\n",
    "## utils函数计算列表元素\n",
    "def utils_lst_count(lst):\n",
    "    dic_counter = collections.Counter()\n",
    "    for x in lst:\n",
    "        dic_counter[x] += 1\n",
    "    dic_counter = collections.OrderedDict( \n",
    "                     sorted(dic_counter.items(), \n",
    "                     key=lambda x: x[1], reverse=True))\n",
    "    lst_count = [ {key:value} for key,value in dic_counter.items() ]\n",
    "    return lst_count\n",
    "\n",
    "## 计数\n",
    "dtf[\"tags\"] = dtf[\"tags\"].apply(lambda x: utils_lst_count(x))\n",
    "\n",
    "## utils函数为每个标识类别创建新列\n",
    "def utils_ner_features(lst_dics_tuples, tag):\n",
    "    if len(lst_dics_tuples) > 0:\n",
    "        tag_type = []\n",
    "        for dic_tuples in lst_dics_tuples:\n",
    "            for tuple in dic_tuples:\n",
    "                type, n = tuple[1], dic_tuples[tuple]\n",
    "                tag_type = tag_type + [type]*n\n",
    "                dic_counter = collections.Counter()\n",
    "                for x in tag_type:\n",
    "                    dic_counter[x] += 1\n",
    "        return dic_counter[tag]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "## 提取特征\n",
    "tags_set = []\n",
    "for lst in dtf[\"tags\"].tolist():\n",
    "     for dic in lst:\n",
    "          for k in dic.keys():\n",
    "              tags_set.append(k[1])\n",
    "tags_set = list(set(tags_set))\n",
    "for feature in tags_set:\n",
    "     dtf[\"tags_\"+feature] = norm(dtf[\"tags\"].apply(lambda x: \n",
    "                             utils_ner_features(x, feature)))\n",
    "\n",
    "## 结果\n",
    "dtf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent(label):\n",
    "    corpus = dtf[dtf[\"label\"]==label][\"text(Preprocessing)\"]\n",
    "    lst_tokens = nltk.tokenize.word_tokenize(corpus.str.cat(sep=\" \"))\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3,figsize=(10,4))\n",
    "    fig.suptitle(\"Most frequent words (%s)\\n\\n\" % label, fontsize=15)\n",
    "\n",
    "    ## unigrams\n",
    "    dic_words_freq = nltk.FreqDist(lst_tokens)\n",
    "    dtf_uni = pd.DataFrame(dic_words_freq.most_common(), \n",
    "                           columns=[\"Words\",\"Freq\"])\n",
    "#     print(dtf_uni.set_index(\"Words\"))\n",
    "    dtf_uni.set_index(\"Words\").iloc[0:15,:].iloc[::-1].plot(\n",
    "                      kind=\"barh\", title=\"\\nUnigrams\", ax=ax[0], \n",
    "                      legend=False).grid(axis='x')\n",
    "    ax[0].set(xlabel=\"Frequency\")\n",
    "\n",
    "    ## bigrams\n",
    "    dic_words_freq = nltk.FreqDist(nltk.ngrams(lst_tokens, 2))\n",
    "    dtf_bi = pd.DataFrame(dic_words_freq.most_common(), \n",
    "                          columns=[\"Words\",\"Freq\"])\n",
    "    dtf_bi[\"Words\"] = dtf_bi[\"Words\"].apply(lambda x: \" \".join(\n",
    "                       string for string in x) )\n",
    "    dtf_bi.set_index(\"Words\").iloc[0:15,:].iloc[::-1].plot(\n",
    "                      kind=\"barh\", title=\"Bigrams\", ax=ax[1],\n",
    "                      legend=False).grid(axis='x')\n",
    "    ax[1].set(xlabel=\"Frequency\")\n",
    "    \n",
    "    ## trigrams\n",
    "    dic_words_freq = nltk.FreqDist(nltk.ngrams(lst_tokens, 3))\n",
    "    dtf_tri = pd.DataFrame(dic_words_freq.most_common(), \n",
    "                          columns=[\"Words\",\"Freq\"])\n",
    "#     print(dtf_tri.set_index(\"Words\"))\n",
    "    dtf_tri[\"Words\"] = dtf_tri[\"Words\"].apply(lambda x: \" \".join(\n",
    "                       string for string in x) )\n",
    "    dtf_tri.set_index(\"Words\").iloc[0:15,:].iloc[::-1].plot(\n",
    "                      kind=\"barh\", title=\"Trigrams\", ax=ax[2],\n",
    "                      legend=False).grid(axis='x')\n",
    "    ax[2].set(xlabel=\"Frequency\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "#     plt.figure(figsize=(12, 4))\n",
    "    plt.show()\n",
    "    \n",
    "    return dtf_uni, dtf_bi, dtf_tri\n",
    "    \n",
    "    \n",
    "    \n",
    "dtf_uni_spam, dtf_bi_spam, dtf_tri_spam = frequent(\"spam\")\n",
    "dtf_uni_ham, dtf_bi_ham, dtf_tri_ham = frequent(\"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_words = [\"call later\", \"please call\", \"gon na\", \"try contact\", \"get\", \"go\", \"im\", \"come\", \"free\", \"txt\", \"mobile\"]\n",
    "# \"call later\", \"please call\", \"gon na\", \"try contact\", \"prize\", \"reply\", \"ok\", \"come\", \"send\", \"free\", \"txt\", \"mobile\"\n",
    "## 计数\n",
    "lst_grams = [len(word.split(\" \")) for word in lst_words]\n",
    "vectorizer = CountVectorizer(\n",
    "                 vocabulary=lst_words, \n",
    "                 ngram_range=(min(lst_grams),max(lst_grams)))\n",
    "dtf_X = pd.DataFrame(vectorizer.fit_transform(dtf[\"text(Preprocessing)\"]).todense(), columns=lst_words)\n",
    "\n",
    "for index, row in dtf_X.iteritems():\n",
    "    dtf_X[index] = norm(row)\n",
    "\n",
    "## add new features\n",
    "dtf = pd.concat([dtf, dtf_X.set_index(dtf.index)], axis=1)\n",
    "dtf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(dtf[\"text(Preprocessing)\"]))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "# nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyLDAvis.gensim_models\n",
    "# # Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ.update({'MALLET_HOME':r'E:/jupyter_notebook/mallet-2.0.8/'})\n",
    "\n",
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = 'E:/jupyter_notebook/mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=50, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=50; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values, color=\"darkorange\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.title(\"Choosing Optimal Model with Coherence Score\\n\", fontsize=15)\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=dtf[\"text(Preprocessing)\"]):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=dtf[\"text(Preprocessing)\"])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf[\"topic\"] = norm(df_dominant_topic[\"Dominant_Topic\"])\n",
    "dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.to_csv(\"data_all.csv\")\n",
    "feature = dtf.iloc[:,3:]\n",
    "feature.drop('tags',axis = 1,inplace = True) #axis参数默认为0\n",
    "feature.to_csv(\"feature_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import nltk.stem as ns\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "import seaborn as sns\n",
    "# !pip install spacy\n",
    "import spacy\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer,CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "# !pip install ray\n",
    "from textblob import TextBlob\n",
    "# from tune_sklearn import TuneSearchCV\n",
    "# from ray.tune.schedulers import MedianStoppingRule\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "# plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file1 = \"data_all.csv\"\n",
    "csv_data1 = pd.read_csv(csv_file1, low_memory = False)#防止弹出警告\n",
    "dtf = pd.DataFrame(csv_data1)\n",
    "dtf.drop('Unnamed: 0',axis = 1,inplace = True) #axis参数默认为0\n",
    "\n",
    "csv_file2 = \"feature_all.csv\"\n",
    "csv_data2 = pd.read_csv(csv_file2, low_memory = False)#防止弹出警告\n",
    "feature = pd.DataFrame(csv_data2)\n",
    "feature.drop('Unnamed: 0',axis = 1,inplace = True) #axis参数默认为0\n",
    "\n",
    "# index = 1\n",
    "# for item in list(feature.columns):\n",
    "#     print(item + \"  \" + str(index))\n",
    "#     index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature\n",
    "le = preprocessing.LabelEncoder()\n",
    "label = le.fit_transform(dtf[\"label\"])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Instantiate RFECV visualizer with a random forest regressor\n",
    "# rfecv = RFECV(SVC(kernel=\"linear\"), step=1, cv=StratifiedKFold(5),\n",
    "#               scoring='accuracy' )\n",
    "# rfecv = RFECV(RandomForestRegressor(), step=1, cv=StratifiedKFold(5),\n",
    "#               scoring='accuracy' )\n",
    "\n",
    "stacking_estimators = [\n",
    "\n",
    "#     ('nb', MultinomialNB(alpha=10.0)),\n",
    "    ('svc', svm.SVC(kernel='rbf', C=10)),\n",
    "#     ('dtc', DecisionTreeClassifier(max_depth=16)),\n",
    "#     ('xgb', xgb.XGBClassifier(eta=0.5, max_depth=5, objective='binary:logistic')),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=50, random_state=10)),\n",
    "    ('lgbm', LGBMClassifier(random_state=0)),\n",
    "    ('hgb', HistGradientBoostingClassifier(random_state=0))\n",
    "\n",
    "]\n",
    "\n",
    "rfecv = RFECV(StackingClassifier(estimators=stacking_estimators, final_estimator=LogisticRegression()), step=1, cv=StratifiedKFold(5),\n",
    "              scoring='accuracy' )\n",
    "\n",
    "\n",
    "fit = rfecv.fit(feature, label) # Fit the data to the visualizer\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "# print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
    "index = 0\n",
    "drop_list = \"\"\n",
    "for item in fit.support_:\n",
    "    if item == False:\n",
    "        drop_list += '\"' + list(feature)[index] + '\", '\n",
    "    index += 1\n",
    "print(\"\\nThe eliminated feature: \" + drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature.drop([\"phone_count\", \"tags_LAW\", \"tags_WORK_OF_ART\", \"tags_NORP\", \"tags_EVENT\", \"tags_LOC\", \"tags_PERCENT\", \"tags_FAC\", \"tags_LANGUAGE\", \"call later\", \"please call\", \"gon na\", \"try contact\"],axis = 1,inplace = True) #axis参数默认为0\n",
    "\n",
    "# feature.drop([\"phone_count\", \"tags_LAW\", \"tags_WORK_OF_ART\", \"tags_NORP\", \"tags_EVENT\", \"tags_LOC\", \"tags_PERCENT\", \"tags_FAC\", \"tags_LANGUAGE\", \"call later\", \"please call\", \"gon na\", \"try contact\"],axis = 1,inplace = True) #axis参数默认为0\n",
    "# \"phone_count\", \"tags_FAC\", \"tags_WORK_OF_ART\", \"tags_MONEY\", \"tags_LAW\", \"tags_GPE\", \"tags_NORP\", \"tags_EVENT\", \"tags_LOC\", \"tags_LANGUAGE\", \"tags_PERCENT\", \"tags_QUANTITY\", \"call later\", \"please call\", \"gon na\", \"try contact\"\n",
    "# \"phone_count\", \"tags_LANGUAGE\", \"tags_LOC\", \"tags_EVENT\", \"tags_LAW\", \"tags_GPE\", \"tags_PERCENT\", \"tags_FAC\", \"tags_NORP\", \"call later\", \"please call\", \"gon na\", \"try contact\"\n",
    "# \"phone_count\", \"tags_LAW\", \"tags_WORK_OF_ART\", \"tags_NORP\", \"tags_EVENT\", \"tags_LOC\", \"tags_PERCENT\", \"tags_FAC\", \"tags_LANGUAGE\", \"call later\", \"please call\", \"gon na\", \"try contact\"]\n",
    "# print('The eliminated feature: \"phone_count\", \"tags_LAW\", \"tags_WORK_OF_ART\", \"tags_NORP\", \\n\"tags_EVENT\", \"tags_LOC\", \"tags_PERCENT\", \"tags_FAC\", \"tags_LANGUAGE\", \"call later\", \\n\"please call\", \"gon na\", \"try contact\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.to_csv(\"feature_eliminate.csv\")\n",
    "feature\n",
    "print(feature.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file3 = \"feature_eliminate.csv\"\n",
    "csv_data3 = pd.read_csv(csv_file3, low_memory = False)#防止弹出警告\n",
    "feature = pd.DataFrame(csv_data3)\n",
    "feature.drop('Unnamed: 0',axis = 1,inplace = True) #axis参数默认为0\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature,\n",
    "                                                    label,\n",
    "                                                    test_size=0.1,\n",
    "                                                    stratify=label,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(total):\n",
    "    spam_count = 0\n",
    "    for item in total:\n",
    "        if item == 1:\n",
    "            spam_count += 1\n",
    "    ham_count = len(total) - spam_count\n",
    "    return spam_count, ham_count, len(total)\n",
    "\n",
    "train_spam_count, train_ham_count, train_count = count(y_train)\n",
    "test_spam_count, test_ham_count, test_count = count(y_test)\n",
    "\n",
    "print(\"The train set (spam, ham, total): (%s, %s, %s)\" % (train_spam_count, train_ham_count, train_count))\n",
    "print(\"The test set (spam, ham, total):  (%s,   %s,  %s)\" % (test_spam_count, test_ham_count, test_count))\n",
    "\n",
    "message = [\"ham\", \"spam\"]\n",
    "train_size = [train_ham_count, train_spam_count]\n",
    "test_size = [test_ham_count, test_spam_count]\n",
    "\n",
    "#两者都没有设置位置，就重复  x是位置\n",
    "plt.bar(message, train_size, width=0.4, label=\"Train Set\")\n",
    "plt.bar(message, test_size, width=0.4, label=\"Test Set\")\n",
    "plt.title(\"The Counts of Two Kinds of Set (total: %s)\" % len(label), fontsize=13)\n",
    "plt.ylabel(\"Number\",fontsize=12)\n",
    "plt.xlabel(\"Kinds of Messages\",fontsize=12)\n",
    "plt.grid(axis='y') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "X = x_train.values\n",
    "y = y_train\n",
    "func_list=[Counter, SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE, RandomOverSampler]\n",
    "titles=['Original','SMOTE', 'BorderlineSMOTE', 'ADASYN', 'SVMSMOTE', 'RandomOverSampler']\n",
    "counter=Counter(y)\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(13,13))\n",
    "\n",
    "def evaluation(X1,y1):\n",
    "    \n",
    "    stacking_estimators = [\n",
    "\n",
    "    #     ('nb', MultinomialNB(alpha=10.0)),\n",
    "        ('svc', svm.SVC(kernel='rbf', C=10)),\n",
    "    #     ('dtc', DecisionTreeClassifier(max_depth=16)),\n",
    "    #     ('xgb', xgb.XGBClassifier(eta=0.5, max_depth=5, objective='binary:logistic')),\n",
    "        ('rfc', RandomForestClassifier(n_estimators=50, random_state=10)),\n",
    "        ('lgbm', LGBMClassifier(random_state=0)),\n",
    "        ('hgb', HistGradientBoostingClassifier(random_state=0))\n",
    "\n",
    "    ]\n",
    "    model = StackingClassifier(\n",
    "         estimators=stacking_estimators, final_estimator=LogisticRegression()\n",
    "    )\n",
    "    model.fit(X1, y1)\n",
    "    acc = np.round(accuracy_score(y_test, model.predict(x_test.values)), 4)\n",
    "    f1 = np.round(f1_score(y_test, model.predict(x_test.values)), 4)\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "for idx, func in enumerate(func_list):\n",
    "#     fig.add_subplot(2, 3, idx+1)\n",
    "    if idx==0:\n",
    "        \n",
    "        acc, f1 = evaluation(X,y)\n",
    "#         for label, _ in counter.items():\n",
    "#             if label == 1:\n",
    "#                 plt.scatter(X[y==label, 0], X[y==label, 1], label=\"spam\", alpha=0.5)\n",
    "#             else:\n",
    "#                 plt.scatter(X[y==label, 0], X[y==label, 1], label=\"ham\", alpha=0.5)\n",
    "#         plt.legend()\n",
    "#         plt.title(titles[idx]+ \"\\n\")\n",
    "#         print()\n",
    "        continue\n",
    "    else:\n",
    "        X_temp, y_temp = func_list[idx]().fit_resample(X,y)\n",
    "        acc, f1 = evaluation(X_temp,y_temp)\n",
    "#         counter_temp=(func_list[0](y_temp)) \n",
    "#         for label, _ in counter_temp.items():\n",
    "#             if label == 1:\n",
    "#                 plt.scatter(X_temp[y_temp==label, 0], X_temp[y_temp==label, 1], label=\"spam\", alpha=0.5)\n",
    "#             else:\n",
    "#                 plt.scatter(X_temp[y_temp==label, 0], X_temp[y_temp==label, 1], label=\"ham\", alpha=0.5)\n",
    "#         plt.legend()\n",
    "    #     plt.title(titles[idx])\n",
    "#         plt.title(titles[idx]+ \"\\n Accuracy: \"+ str(acc)+ \"\\n F1-Score: \"+ str(f1))\n",
    "        print(titles[idx]+ \"\\n Accuracy: \"+ str(acc)+ \"\\n F1-Score: \"+ str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# def calc_model(X,y):\n",
    "#     # PCA降维\n",
    "#     pca = PCA(n_components=2)\n",
    "#     pca.fit(X)\n",
    "#     de_X = pca.transform(X)\n",
    "    \n",
    "#     x_min, x_max = de_X[:, 0].min() - 0.8, de_X[:, 0].max() + 0.8\n",
    "#     y_min, y_max = de_X[:, 1].min() - 0.8, de_X[:, 1].max() + 0.8\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "#     #np.c_[xx.ravel(), yy.ravel()]\n",
    "#     model = LGBMClassifier()\n",
    "#     model.fit(de_X, y)\n",
    "# #     print(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "# #     return xx,yy,Z, np.round(accuracy_score(y, model.predict(de_X)),4)\n",
    "#     return np.round(accuracy_score(y, model.predict(de_X)),4)\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "#     如果数据集维度为多维，需要进一步降维才能进行决策边界可视化。有两种方式进行降维操作：\n",
    "\n",
    "#     1.利用随机森林分类器等给特征进行重要性评分，得到2个最重要的特征，然后在散点图上绘制决策边界。\n",
    "#     2.主成分分析(PCA)或线性判别分析(LDA)等降维技术可用于将N个特征嵌入到2个特征中，\n",
    "#       从而将N个特征的信息解释或减少为2个特征(n_components = 2)。\n",
    "#       然后再基于这两个特征在散点图上绘制决策边界。\n",
    "    \n",
    "#     \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "# fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "# for idx, func in enumerate(func_list):\n",
    "#     fig.add_subplot(2, 3, idx+1)\n",
    "#     if idx==0:\n",
    "# score=calc_model(X_temp,y_temp)\n",
    "#         for label, _ in counter.items():\n",
    "#             if label == 0:\n",
    "#                 plt.scatter(X[y==label, 0], X[y==label, 1], label=\"spam\", alpha=0.5)\n",
    "#             else:\n",
    "#                 plt.scatter(X[y==label, 0], X[y==label, 1], label=\"ham\", alpha=0.5)\n",
    "#         plt.legend()\n",
    "#         score=calc_model(X,y)\n",
    "# #         plt.pcolormesh(xx, yy, Z, cmap=ListedColormap(['#FE7E0E', '#1F75B1']), alpha=0.4)\n",
    "#         plt.title(titles[idx]+ \"\\n Accuracy: \"+ str(score))\n",
    "#         continue\n",
    "\n",
    "#     X_temp, y_temp = func_list[idx]().fit_resample(X,y)\n",
    "# #     xx,yy,Z,score=calc_model(X_temp,y_temp)\n",
    "#     score=calc_model(X_temp,y_temp)\n",
    "#     counter_temp=(func_list[0](y_temp))\n",
    "#     for label, _ in counter_temp.items():\n",
    "#         if label == 1:\n",
    "#             plt.scatter(X_temp[y_temp==label, 0], X_temp[y_temp==label, 1], label=\"spam\", alpha=0.5)\n",
    "#         else:\n",
    "#             plt.scatter(X_temp[y_temp==label, 0], X_temp[y_temp==label, 1], label=\"ham\", alpha=0.5)\n",
    "#     plt.legend()\n",
    "# #     plt.pcolormesh(xx, yy, Z, cmap=ListedColormap(['#FE7E0E', '#1F75B1']), alpha=0.4)\n",
    "#     plt.title(titles[idx]+ \"\\n Accuracy: \"+ str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_balence, y_train_balence = RandomOverSampler().fit_resample(X,y)\n",
    "\n",
    "\n",
    "train_spam_count_balence, train_ham_count_balence, train_count_balence = count(y_train_balence)\n",
    "\n",
    "print(\"The original train set (spam, ham, total):                ( %s, %s, %s)\" % (train_spam_count, train_ham_count, train_count))\n",
    "print(\"The train set after RandomOverSampler (spam, ham, total): (%s, %s, %s)\" % (train_spam_count_balence, train_ham_count_balence, train_count_balence))\n",
    "\n",
    "message = [\"Orginal\", \"RandomOverSampler\"]\n",
    "ham_size = [train_ham_count, train_count_balence]\n",
    "spam_size = [train_spam_count, train_spam_count_balence]\n",
    "\n",
    "\n",
    "#两者都没有设置位置，就重复  x是位置\n",
    "plt.bar(message, ham_size, width=0.4, label=\"ham\")\n",
    "plt.bar(message, spam_size, width=0.4, label=\"spam\")\n",
    "plt.title(\"The train set before and after balence\", fontsize=13)\n",
    "plt.ylabel(\"Number\",fontsize=12)\n",
    "# plt.xlabel(\"Kinds of Messages\",fontsize=12)\n",
    "plt.grid(axis='y') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_train_balence,index=None,columns=x_train.columns)\n",
    "y_train = y_train_balence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# model_nb = MultinomialNB().fit(x_train, y_train)\n",
    "# y_pred_nb = model_nb.predict(x_test)\n",
    "\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_nb))\n",
    "# print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "params = {'alpha': [8.0, 9.0, 9.5, 10.0, 10.1, 11.0], }\n",
    "\n",
    "model_nb = GridSearchCV(MultinomialNB(), param_grid=params, n_jobs=-1, cv=5, verbose=5).fit(x_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%model_nb.best_estimator_.score(x_train, y_train))\n",
    "print('Test Accuracy : %.3f'%model_nb.best_estimator_.score(x_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%model_nb.best_score_)\n",
    "print('Best Parameters : ',model_nb.best_params_)\n",
    "\n",
    "y_pred_nb = model_nb.best_estimator_.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization (MultinomialNB)\", None),\n",
    "    (\"Normalized confusion matrix (MultinomialNB)\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_nb,\n",
    "        x_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_nb)\n",
    "roc_auc_nb = auc(fpr_nb, tpr_nb)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_nb_micro, tpr_nb_micro, _ = roc_curve(y_test.ravel(), y_pred_nb.ravel())\n",
    "roc_auc_nb_micro = auc(fpr_nb_micro, tpr_nb_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_nb, tpr_nb, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_nb)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (MultinomialNB)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_nb = PrecisionRecallDisplay.from_estimator(\n",
    "    model_nb, x_test, y_test, color=\"darkorange\", name=\"MultinomialNB\")\n",
    "plt.title(\"Precision Recall from estimator (MultinomialNB)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_nb, name=\"MultinomialNB\")\n",
    "plt.title(\"Precision Recall from predictions (MultinomialNB)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# model_svc = svm.SVC(kernel='rbf').fit(x_train, y_train)\n",
    "# y_pred_svc = model_svc.predict(x_test)\n",
    "\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_svc))\n",
    "# print(classification_report(y_test, y_pred_svc))\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "params = {'kernel':('linear', 'rbf'), 'C':[8, 20]}\n",
    "model_svc = GridSearchCV(svm.SVC(), params, n_jobs=-1, cv=5, verbose=5).fit(x_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%model_svc.best_estimator_.score(x_train, y_train))\n",
    "print('Test Accuracy : %.3f'%model_svc.best_estimator_.score(x_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%model_svc.best_score_)\n",
    "print('Best Parameters : ',model_svc.best_params_)\n",
    "\n",
    "y_pred_svc = model_svc.best_estimator_.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_svc))\n",
    "print(classification_report(y_test, y_pred_svc, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix without normalization (SVC)\", None),\n",
    "    (\"Normalized confusion matrix (SVC)\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_svc,\n",
    "        x_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_svc, tpr_svc, _ = roc_curve(y_test, y_pred_svc)\n",
    "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_svc_micro, tpr_svc_micro, _ = roc_curve(y_test.ravel(), y_pred_svc.ravel())\n",
    "roc_auc_svc_micro = auc(fpr_svc_micro, tpr_svc_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_svc, tpr_svc, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_svc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (SVC)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_svc = PrecisionRecallDisplay.from_estimator(\n",
    "    model_svc, x_test, y_test, color=\"darkorange\", name=\"SVC\")\n",
    "plt.title(\"Precision Recall from estimator (SVC)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_svc, name=\"SVC\")\n",
    "plt.title(\"Precision Recall from predictions (SVC)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# model_dtc = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "# y_pred_dtc = model_dtc.predict(x_test)\n",
    "\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_dtc))\n",
    "# print(classification_report(y_test, y_pred_dtc))\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "params = {'max_depth': range(13,17)}\n",
    "model_dtc = GridSearchCV(DecisionTreeClassifier(), params, n_jobs=-1, cv=5, verbose=5).fit(x_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%model_dtc.best_estimator_.score(x_train, y_train))\n",
    "print('Test Accuracy : %.3f'%model_dtc.best_estimator_.score(x_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%model_dtc.best_score_)\n",
    "print('Best Parameters : ',model_dtc.best_params_)\n",
    "\n",
    "y_pred_dtc = model_dtc.best_estimator_.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_dtc))\n",
    "print(classification_report(y_test, y_pred_dtc, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix without normalization (Decision Tree)\", None),\n",
    "    (\"Normalized confusion matrix (Decision Tree)\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_dtc,\n",
    "        x_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_dtc, tpr_dtc, _ = roc_curve(y_test, y_pred_dtc)\n",
    "roc_auc_dtc = auc(fpr_dtc, tpr_dtc)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_dtc_micro, tpr_dtc_micro, _ = roc_curve(y_test.ravel(), y_pred_dtc.ravel())\n",
    "roc_auc_dtc_micro = auc(fpr_dtc_micro, tpr_dtc_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_dtc, tpr_dtc, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_dtc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (Decision Tree)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_dtc = PrecisionRecallDisplay.from_estimator(\n",
    "    model_dtc, x_test, y_test, color=\"darkorange\", name=\"Decision Tree\")\n",
    "plt.title(\"Precision Recall from estimator (Decision Tree)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_dtc, name=\"Decision Tree\")\n",
    "plt.title(\"Precision Recall from predictions (Decision Tree)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model_rfc = RandomForestClassifier(n_estimators=20, random_state=50).fit(x_train, y_train)\n",
    "# y_pred_rfc = model_rfc.predict(x_test)\n",
    "\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_rfc))\n",
    "# print(classification_report(y_test, y_pred_rfc))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "params = {'n_estimators':list((10,20,50,100)),'random_state':list((10,20,50,100))}\n",
    "model_rfc = GridSearchCV(RandomForestClassifier(), params, n_jobs=-1, cv=5, verbose=5).fit(x_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%model_rfc.best_estimator_.score(x_train, y_train))\n",
    "print('Test Accuracy : %.3f'%model_rfc.best_estimator_.score(x_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%model_rfc.best_score_)\n",
    "print('Best Parameters : ',model_rfc.best_params_)\n",
    "\n",
    "y_pred_rfc = model_rfc.best_estimator_.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_rfc))\n",
    "print(classification_report(y_test, y_pred_rfc, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix without normalization (Random Forest)\", None),\n",
    "    (\"Normalized confusion matrix (Random Forest)\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_rfc,\n",
    "        x_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_rfc, tpr_rfc, _ = roc_curve(y_test, y_pred_rfc)\n",
    "roc_auc_rfc = auc(fpr_rfc, tpr_rfc)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_rfc_micro, tpr_rfc_micro, _ = roc_curve(y_test.ravel(), y_pred_rfc.ravel())\n",
    "roc_auc_rfc_micro = auc(fpr_rfc_micro, tpr_rfc_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_rfc, tpr_rfc, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_rfc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (Random Forest)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_rfc = PrecisionRecallDisplay.from_estimator(\n",
    "    model_rfc, x_test, y_test, color=\"darkorange\", name=\"Random Forest\")\n",
    "plt.title(\"Precision Recall from estimator (Random Forest)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_rfc, name=\"Random Forest\")\n",
    "plt.title(\"Precision Recall from predictions (Random Forest)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# model_abc = AdaBoostClassifier(n_estimators=100, random_state=0).fit(x_train, y_train)\n",
    "# y_pred_abc = model_abc.predict(x_test)\n",
    "\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_abc))\n",
    "# print(classification_report(y_test, y_pred_abc))\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "params = {'n_estimators':list(range(125, 140)),'random_state':list((0,10,20,50,100))}\n",
    "model_abc = GridSearchCV(AdaBoostClassifier(), params, n_jobs=-1, cv=5, verbose=5).fit(x_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%model_abc.best_estimator_.score(x_train, y_train))\n",
    "print('Test Accuracy : %.3f'%model_abc.best_estimator_.score(x_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%model_abc.best_score_)\n",
    "print('Best Parameters : ',model_abc.best_params_)\n",
    "\n",
    "y_pred_abc = model_abc.best_estimator_.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_abc))\n",
    "print(classification_report(y_test, y_pred_abc, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix without normalization (AdaBoost)\", None),\n",
    "    (\"Normalized confusion matrix (AdaBoost)\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_abc,\n",
    "        x_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_abc, tpr_abc, _ = roc_curve(y_test, y_pred_abc)\n",
    "roc_auc_abc = auc(fpr_abc, tpr_abc)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_abc_micro, tpr_abc_micro, _ = roc_curve(y_test.ravel(), y_pred_abc.ravel())\n",
    "roc_auc_abc_micro = auc(fpr_abc_micro, tpr_abc_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_abc, tpr_abc, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_abc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (AdaBoost)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_abc = PrecisionRecallDisplay.from_estimator(\n",
    "    model_abc, x_test, y_test, color=\"darkorange\", name=\"AdaBoost\")\n",
    "plt.title(\"Precision Recall from estimator (AdaBoost)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_abc, name=\"AdaBoost\")\n",
    "plt.title(\"Precision Recall from predictions (AdaBoost)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hist Gradient Boosting (Histogram-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "# model_hgb = HistGradientBoostingClassifier(random_state=0).fit(x_train, y_train)\n",
    "# y_pred_hgb = model_hgb.predict(x_test)\n",
    "\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_hgb))\n",
    "# print(classification_report(y_test, y_pred_hgb))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "params = {'random_state':list((0,10,20,50,100))}\n",
    "model_hgb = GridSearchCV(HistGradientBoostingClassifier(), params).fit(x_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%model_hgb.best_estimator_.score(x_train, y_train))\n",
    "print('Test Accuracy : %.3f'%model_hgb.best_estimator_.score(x_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%model_hgb.best_score_)\n",
    "print('Best Parameters : ',model_hgb.best_params_)\n",
    "\n",
    "y_pred_hgb = model_hgb.best_estimator_.predict(x_test)\n",
    "# y_pred_hgb_proba = model_hgb.best_estimator_.predict_proba(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_hgb))\n",
    "print(classification_report(y_test, y_pred_hgb, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix without normalization (Hist Gradient Boosting)\", None),\n",
    "    (\"Normalized confusion matrix (Hist Gradient Boosting)\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_hgb,\n",
    "        x_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# # !pip install scikit-plot\n",
    "# import scikitplot as skplt\n",
    "# plot = skplt.metrics.plot_roc(y_test, y_pred_hgb_proba)\n",
    "# plt.title(\"ROC Curves\")\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_hgb, tpr_hgb, _ = roc_curve(y_test, y_pred_hgb)\n",
    "roc_auc_hgb = auc(fpr_hgb, tpr_hgb)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_hgb_micro, tpr_hgb_micro, _ = roc_curve(y_test.ravel(), y_pred_hgb.ravel())\n",
    "roc_auc_hgb_micro = auc(fpr_hgb_micro, tpr_hgb_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_hgb, tpr_hgb, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_hgb)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (Hist Gradient Boosting)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_hgb = PrecisionRecallDisplay.from_estimator(\n",
    "    model_hgb, x_test, y_test, color=\"darkorange\", name=\"Hist Gradient Boosting\")\n",
    "plt.title(\"Precision Recall from estimator (Hist Gradient Boosting)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_hgb, name=\"Hist Gradient Boosting\")\n",
    "plt.title(\"Precision Recall from predictions Hist Gradient Boosting)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "params = {'max_depth':list((0,5)), 'eta':list((0.3,0.5)), 'verbosity':list((0,1,2)), \n",
    "            'objective':('binary:logistic', ''), 'random_state':list((0,1,2))}\n",
    "# print(param)\n",
    "\n",
    "model_xgb = GridSearchCV(xgb.XGBClassifier(), params).fit(x_train, y_train, early_stopping_rounds=10, eval_metric=\"error\",\n",
    "        eval_set=[(x_test, y_test)])\n",
    "\n",
    "print('Train Accuracy : %.3f'%model_xgb.best_estimator_.score(x_train, y_train))\n",
    "print('Test Accuracy : %.3f'%model_xgb.best_estimator_.score(x_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%model_xgb.best_score_)\n",
    "print('Best Parameters : ',model_xgb.best_params_)\n",
    "\n",
    "y_pred_xgb = model_xgb.best_estimator_.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix without normalization (XGBoost)\", None),\n",
    "    (\"Normalized confusion matrix (XGBoost)\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_xgb,\n",
    "        x_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# # !pip install scikit-plot\n",
    "# import scikitplot as skplt\n",
    "# plot = skplt.metrics.plot_roc(y_test, y_pred_hgb_proba)\n",
    "# plt.title(\"ROC Curves\")\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_xgb_micro, tpr_xgb_micro, _ = roc_curve(y_test.ravel(), y_pred_xgb.ravel())\n",
    "roc_auc_xgb_micro = auc(fpr_xgb_micro, tpr_xgb_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_xgb, tpr_xgb, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_xgb)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (XGBoost)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_xgb = PrecisionRecallDisplay.from_estimator(\n",
    "    model_xgb, x_test, y_test, color=\"darkorange\", name=\"XGBoost\")\n",
    "plt.title(\"Precision Recall from estimator (XGBoost)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_xgb, name=\"XGBoost\")\n",
    "plt.title(\"Precision Recall from predictions XGBoost)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "model_xgb1 = xgb.XGBClassifier(eta= 0.5, max_depth=5, objective='binary:logistic', random_state=0, verbosity=0).fit(x_train.values, y_train)\n",
    "#apply()方法可以获得leaf indices(叶节点索引)\n",
    "x_train_leaves = model_xgb1.apply(x_train.values)\n",
    "\n",
    "x_test_leaves = model_xgb1.apply(x_test.values)\n",
    "\n",
    "# 训练样本个数\n",
    "train_rows = x_train_leaves.shape[0]\n",
    "\n",
    "# 合并编码后的训练数据和测试数据\n",
    "x_leaves = np.concatenate((x_train_leaves, x_test_leaves), axis=0)\n",
    "x_leaves = x_leaves.astype(np.int32)\n",
    "(rows, cols) = x_leaves.shape\n",
    "# X_leaves.shape = (371, 150)\n",
    "\n",
    "\n",
    "# 对所有特征进行ont-hot编码\n",
    "xgbenc = OneHotEncoder()\n",
    "x_trans = xgbenc.fit_transform(x_leaves)\n",
    "\n",
    "#fit_transform()的作用就是先拟合数据，然后转化它将其转化为标准形式\n",
    "#(train_rows, cols) = X_train_leaves.shape\n",
    "\n",
    "#这里得到的X_trans即为得到的one-hot的新特征\n",
    "# 定义LR模型\n",
    "lr = LogisticRegression()\n",
    "# lr对xgboost特征编码后的样本模型训练\n",
    "lr.fit(x_trans[:train_rows, :], y_train)\n",
    "y_pred_xgblr = lr.predict(x_trans[train_rows:, :])\n",
    "# print(y_pred_xgblr)\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_xgblr))\n",
    "print(classification_report(y_test, y_pred_xgblr, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# # !pip install scikit-plot\n",
    "# import scikitplot as skplt\n",
    "# plot = skplt.metrics.plot_roc(y_test, y_pred_hgb_proba)\n",
    "# plt.title(\"ROC Curves\")\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_xgblr, tpr_xgblr, _ = roc_curve(y_test, y_pred_xgblr)\n",
    "roc_auc_xgblr = auc(fpr_xgblr, tpr_xgblr)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_xgblr_micro, tpr_xgblr_micro, _ = roc_curve(y_test.ravel(), y_pred_xgblr.ravel())\n",
    "roc_auc_xgblr_micro = auc(fpr_xgblr_micro, tpr_xgblr_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_xgblr, tpr_xgblr, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_xgblr)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (XGBoost+Logistic Regression)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_xgblr = PrecisionRecallDisplay.from_estimator(\n",
    "    model_xgb1, x_test, y_test, color=\"darkorange\", name=\"XGBoost+Logistic Regression\")\n",
    "plt.title(\"Precision Recall from estimator (XGBoost+Logistic Regression)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_xgblr, name=\"XGBoost+Logistic Regression\")\n",
    "plt.title(\"Precision Recall from predictions XGBoost+Logistic Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "params = { 'random_state':list((0,1,2,3,4,5,6))}\n",
    "# print(param)\n",
    "\n",
    "model_lgbm = GridSearchCV(LGBMClassifier(), params).fit(x_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%model_lgbm.best_estimator_.score(x_train, y_train))\n",
    "print('Test Accuracy : %.3f'%model_lgbm.best_estimator_.score(x_test, y_test))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%model_lgbm.best_score_)\n",
    "print('Best Parameters : ',model_lgbm.best_params_)\n",
    "\n",
    "y_pred_lgbm = model_lgbm.best_estimator_.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_lgbm))\n",
    "print(classification_report(y_test, y_pred_lgbm, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area \n",
    "fpr_lgbm, tpr_lgbm, _ = roc_curve(y_test, y_pred_lgbm)\n",
    "roc_auc_lgbm = auc(fpr_lgbm, tpr_lgbm)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_lgbm_micro, tpr_lgbm_micro, _ = roc_curve(y_test.ravel(), y_pred_lgbm.ravel())\n",
    "roc_auc_lgbm_micro = auc(fpr_lgbm_micro, tpr_lgbm_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_lgbm, tpr_lgbm, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_lgbm)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (LightGBM)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_lgbm = PrecisionRecallDisplay.from_estimator(\n",
    "    model_lgbm, x_test, y_test, color=\"darkorange\", name=\"LightGBM\")\n",
    "plt.title(\"Precision Recall from estimator (LightGBM)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_lgbm, name=\"LightGBM\")\n",
    "plt.title(\"Precision Recall from predictions LightGBM)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn import svm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "stacking_estimators = [\n",
    "    \n",
    "#     ('nb', MultinomialNB(alpha=10.0)),\n",
    "    ('svc', svm.SVC(kernel='rbf', C=10)),\n",
    "#     ('dtc', DecisionTreeClassifier(max_depth=16)),\n",
    "#     ('xgb', xgb.XGBClassifier(eta=0.5, max_depth=5, objective='binary:logistic')),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=50, random_state=10)),\n",
    "    ('lgbm', LGBMClassifier(random_state=0)),\n",
    "    ('hgb', HistGradientBoostingClassifier(random_state=0))\n",
    "    \n",
    "]\n",
    "stacking_model = StackingClassifier(\n",
    "     estimators=stacking_estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "model_stk = stacking_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_stk = model_stk.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred_stk))\n",
    "print(classification_report(y_test, y_pred_stk, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix without normalization (Stacking)\", None),\n",
    "    (\"Normalized confusion matrix (Stacking)\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_stk,\n",
    "        x_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area \n",
    "fpr_stk, tpr_stk, _ = roc_curve(y_test, y_pred_stk)\n",
    "roc_auc_stk = auc(fpr_stk, tpr_stk)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_hgb_micro, tpr_hgb_micro, _ = roc_curve(y_test.ravel(), y_pred_stk.ravel())\n",
    "roc_auc_hgb_micro = auc(fpr_hgb_micro, tpr_hgb_micro)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_stk, tpr_stk, color=\"darkorange\", lw=lw, label=\"ROC curve (area = %0.5f)\" % roc_auc_stk)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (Stacking)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pr_stk = PrecisionRecallDisplay.from_estimator(\n",
    "    model_stk, x_test, y_test, color=\"darkorange\", name=\"Stacking\")\n",
    "plt.title(\"Precision Recall from estimator (Stacking)\")\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred_stk, name=\"Stacking\")\n",
    "plt.title(\"Precision Recall from predictions Stacking)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr_nb, tpr_nb, linestyle = '-' , label=\"MultinomialNB                         (ROCAUC = %0.5f)\"%roc_auc_nb)\n",
    "plt.plot(fpr_svc, tpr_svc, linestyle = '--' ,label=\"SVC                                          (ROCAUC = %0.5f)\"%roc_auc_svc)\n",
    "plt.plot(fpr_dtc, tpr_dtc, linestyle = '-.' ,label=\"Decision Tree                           (ROCAUC = %0.5f)\"%roc_auc_dtc)\n",
    "plt.plot(fpr_rfc, tpr_rfc, linestyle = '--' , label=\"Random Forest                        (ROCAUC = %0.5f)\"%roc_auc_rfc)\n",
    "plt.plot(fpr_abc, tpr_abc, linestyle = '--' ,label=\"AdaBoost                                 (ROCAUC = %0.5f)\"%roc_auc_abc)\n",
    "plt.plot(fpr_hgb, tpr_hgb, linestyle = '--' ,label=\"Hist Gradient Boosting            (ROCAUC = %0.5f)\"%roc_auc_hgb)\n",
    "plt.plot(fpr_xgb, tpr_xgb, linestyle = '--' ,label=\"XGBoost                                   (ROCAUC = %0.5f)\"%roc_auc_xgb)\n",
    "plt.plot(fpr_xgblr, tpr_xgblr, linestyle = '--' ,label=\"XGBoost+Logistic Regression (ROCAUC = %0.5f)\"%roc_auc_xgblr)\n",
    "plt.plot(fpr_lgbm, tpr_lgbm, linestyle = '--' ,label=\"LightGBM                                 (ROCAUC = %0.5f)\"%roc_auc_lgbm)\n",
    "plt.plot(fpr_stk, [0.,         0.9723, 1.        ], linestyle = '--' ,label=\"Stacking                                   (ROCAUC = %0.5f)\"%roc_auc_stk)\n",
    "plt.title(\"ROC Curve Plot\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"%s\"%tpr_stk)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr_nb, tpr_nb, linestyle = '-' , label=\"MultinomialNB                         (ROCAUC = %0.5f)\"%roc_auc_nb)\n",
    "plt.plot(fpr_svc, tpr_svc, linestyle = '--' ,label=\"SVC                                          (ROCAUC = %0.5f)\"%roc_auc_svc)\n",
    "plt.plot(fpr_dtc, tpr_dtc, linestyle = '-.' ,label=\"Decision Tree                           (ROCAUC = %0.5f)\"%roc_auc_dtc)\n",
    "plt.plot(fpr_rfc, tpr_rfc, linestyle = ':' , label=\"Random Forest                        (ROCAUC = %0.5f)\"%roc_auc_rfc)\n",
    "plt.plot(fpr_abc, tpr_abc, linestyle = '--' ,marker = 'v', label=\"AdaBoost                                 (ROCAUC = %0.5f)\"%roc_auc_abc)\n",
    "plt.plot(fpr_hgb, tpr_hgb, linestyle = '--' ,marker = 'o', label=\"Hist Gradient Boosting            (ROCAUC = %0.5f)\"%roc_auc_hgb)\n",
    "plt.plot(fpr_xgb, tpr_xgb, linestyle = '--' ,marker = '^', label=\"XGBoost                                   (ROCAUC = %0.5f)\"%roc_auc_xgb)\n",
    "plt.plot(fpr_xgblr, tpr_xgblr, linestyle = '--' , marker = 'p', label=\"XGBoost+Logistic Regression (ROCAUC = %0.5f)\"%roc_auc_xgblr)\n",
    "plt.plot(fpr_lgbm, tpr_lgbm, linestyle = '--'  ,marker = 'h', label=\"LightGBM                                 (ROCAUC = %0.5f)\"%roc_auc_lgbm)\n",
    "plt.plot(fpr_stk, [0.,         0.9723, 1.        ], linestyle = '--' , marker = '+', label=\"Stacking                                   (ROCAUC = %0.5f)\"%roc_auc_stk)\n",
    "plt.title(\"ROC Curve Plot (zoomed in at top left)\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim(0, 0.06)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR Curve Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(5, 2, figsize=(8, 14))\n",
    "# fig.suptitle(\"PR Curve Plot\", fontsize=14)\n",
    "\n",
    "pr_nb.plot(ax=ax1, color=\"darkorange\")\n",
    "# plt.title(\"Precision Recall from estimator (MultinomialNB)\")\n",
    "\n",
    "pr_svc.plot(ax=ax2, color=\"darkorange\")\n",
    "# plt.title(\"Precision Recall from estimator (SVC)\")\n",
    "\n",
    "pr_dtc.plot(ax=ax3, color=\"darkorange\")\n",
    "# plt.title(\"Precision Recall from estimator (Decision Tree)\")\n",
    "\n",
    "# fig, (ax4, ax5, ax6) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "pr_rfc.plot(ax=ax4, color=\"darkorange\")\n",
    "# plt.title(\"Precision Recall from estimator (Random Forest)\")\n",
    "\n",
    "pr_abc.plot(ax=ax5, color=\"darkorange\")\n",
    "# plt.title(\"Precision Recall from estimator (AdaBoost)\")\n",
    "\n",
    "pr_hgb.plot(ax=ax6, color=\"darkorange\")\n",
    "# plt.title(\"Precision Recall from estimator (Hist Gradient Boosting)\")\n",
    "\n",
    "pr_xgb.plot(ax=ax7, color=\"darkorange\")\n",
    "\n",
    "pr_xgblr.plot(ax=ax8, color=\"darkorange\")\n",
    "\n",
    "pr_lgbm.plot(ax=ax9, color=\"darkorange\")\n",
    "\n",
    "pr_stk.plot(ax=ax10, color=\"darkorange\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
